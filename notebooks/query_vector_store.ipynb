{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099a9b12",
   "metadata": {},
   "source": [
    "# Advanced Vector Store Queries\n",
    "\n",
    "This notebook demonstrates detailed querying of the Qdrant vector store containing:\n",
    "- **Resume data** (from `resume_ale.md`): work experience, education, skills\n",
    "- **Personality traits** (from `personalities_16.md`): personality, strengths, weaknesses\n",
    "\n",
    "We'll explore:\n",
    "1. Collection metadata and structure\n",
    "2. Filtering by section type\n",
    "3. Viewing embeddings and payloads\n",
    "4. Semantic search examples\n",
    "5. Specific queries for resume vs personality data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb9a043",
   "metadata": {},
   "source": [
    "## 1. Initialize Vector Store Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105c3d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to Qdrant vector store\n",
      "ğŸ“‚ Storage path: c:\\Users\\Ale\\Documents\\Data-Science-Projects\\GitHub\\Resume_Claude_SDK_Agent\\notebooks\\..\\vector_db\\qdrant_storage\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Initialize Qdrant client with local storage\n",
    "storage_path = \"../vector_db/qdrant_storage\"\n",
    "client = QdrantClient(path=storage_path)\n",
    "\n",
    "# Collection name\n",
    "collection_name = \"resume_data\"\n",
    "\n",
    "print(\"âœ… Connected to Qdrant vector store\")\n",
    "print(f\"ğŸ“‚ Storage path: {Path(storage_path).absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c14602",
   "metadata": {},
   "source": [
    "## 2. Explore Collection Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6215e4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Available Collections:\n",
      "   - resume_data\n",
      "\n",
      "ğŸ“Š Collection 'resume_data' Details:\n",
      "   Total documents: 49\n",
      "   Vector dimensions: 1536\n",
      "   Distance metric: Cosine\n",
      "   Status: green\n",
      "\n",
      "ğŸ“ˆ Documents by Section Type:\n",
      "   continuing_studies  :   7 chunks\n",
      "   education           :   2 chunks\n",
      "   personal_info       :   1 chunks\n",
      "   personality         :  14 chunks\n",
      "   professional_summary:   1 chunks\n",
      "   skills              :   5 chunks\n",
      "   work_experience     :  19 chunks\n"
     ]
    }
   ],
   "source": [
    "# Get all collections\n",
    "collections = client.get_collections()\n",
    "print(\"ğŸ“š Available Collections:\")\n",
    "for collection in collections.collections:\n",
    "    print(f\"   - {collection.name}\")\n",
    "\n",
    "# Get detailed collection info\n",
    "if client.collection_exists(collection_name):\n",
    "    collection_info = client.get_collection(collection_name)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Collection '{collection_name}' Details:\")\n",
    "    print(f\"   Total documents: {collection_info.points_count}\")\n",
    "    print(f\"   Vector dimensions: {collection_info.config.params.vectors.size}\")\n",
    "    print(f\"   Distance metric: {collection_info.config.params.vectors.distance}\")\n",
    "    print(f\"   Status: {collection_info.status}\")\n",
    "    \n",
    "    # Count by section type\n",
    "    from collections import Counter\n",
    "    all_records, _ = client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        limit=1000,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "    \n",
    "    section_counts = Counter(r.payload.get('section_type', 'unknown') for r in all_records)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Documents by Section Type:\")\n",
    "    for section, count in sorted(section_counts.items()):\n",
    "        print(f\"   {section:20s}: {count:3d} chunks\")\n",
    "else:\n",
    "    print(f\"âŒ Collection '{collection_name}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b793ad",
   "metadata": {},
   "source": [
    "## 3. Query Resume Data (from resume_ale.md)\n",
    "\n",
    "### 3.1 View Work Experience with Full Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28af347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¼ Work Experience Chunks (showing 19):\n",
      "\n",
      "================================================================================\n",
      "CHUNK 1 - ID: 0a064195-2a60-4559-ac32-61ceb3b48bcb\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Developed a Power BI dashboard to track changes in imported food volumes, collaborating with import inspectors to define metrics and design visualizations in Power BI for stakeholder use.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 2 - ID: 2910f376-6469-4bac-aec3-8627504b7d30\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Automated forecasting and reduced manual effort by 40 hours per month by deploying the forecasting pipeline and scheduling automated runs using Python and Microsoft Fabric.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 3 - ID: 2c05df1d-c331-4805-901d-46968ae5cc41\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Extracted and processed millions of import/export transactions by building web-scraping collectors and a PySpark ETL pipeline to load cleaned data into a Microsoft Fabric lakehouse.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 4 - ID: 56ad2d58-3ec6-43e4-8626-211859949eb3\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Automated data categorization, reducing data cleaning time by over 15 hours per week, by integrating LLM-based classification into the ETL pipeline.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 5 - ID: 5b859e6e-5a8f-4798-b979-7da28716e18a\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Analyst: Built an ETL pipeline integrating five data sources totaling over 1M records using SQL and Python, automating ingestion and cleaning and saving 8 hours weekly in data preparation.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Rubicon Organics\n",
      "   Position:       Data Analyst\n",
      "   Start Date:     March-2023\n",
      "   End Date:       December-2023\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 6 - ID: 5f3aa99a-64bf-4799-9e6f-dee6c99829f5\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Quality Assurance Technician: Performed root cause analyses on non-conforming products, reducing rework and generating cost savings by applying corrective actions informed by statistical analysis in Excel.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        The Very Good Food Company\n",
      "   Position:       Quality Assurance Technician\n",
      "   Start Date:     February-2021\n",
      "   End Date:       February-2022\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 7 - ID: 6a961995-a413-4f0c-9f39-d521e5fa8a88\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist: Analyzed pathogen occurrence trends across 50 facilities by performing statistical analysis with SQL and Power BI and collaborating with inspectors to implement preventive inspections.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist\n",
      "   Start Date:     December-2023\n",
      "   End Date:       March-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 8 - ID: 6ca1d6e8-749e-4391-9524-e96cbcba5941\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Analyst: Built three Power BI dashboards for sales and marketing by collaborating with stakeholders to define requirements and implementing interactive reports in Power BI.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Rubicon Organics\n",
      "   Position:       Data Analyst\n",
      "   Start Date:     March-2023\n",
      "   End Date:       December-2023\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 9 - ID: 98b0d73e-0e2c-4994-851d-b3b029ca6292\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Implemented a Python algorithm to automatically select sampling plans, reducing inspector manual work by 3 hours per inspector per day and generating approximately CAD 4,000,000 in annual savings by translating business rules into an automated algorithm.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 10 - ID: 9b3660fc-68f6-4f1b-856f-7dafeac444ef\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Developed and deployed a time-series forecasting model that achieved 87% accuracy in predicting monthly import/export volumes by training on historical data using Python and time-series ML techniques.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 11 - ID: a7211f9f-0a7a-480a-b119-40af57755a33\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist: Standardized descriptive and statistical reporting in Power BI, reducing report-generation time and improving inspection efficiency by creating templated reports and automated data queries.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist\n",
      "   Start Date:     December-2023\n",
      "   End Date:       March-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 12 - ID: ad2282b9-57a0-4ff6-b70e-0c15233c6a98\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Quality Engineer: Developed an Excel dashboard with automated SQL queries, reducing manual reporting time by 40% and enabling near-real-time quality monitoring by automating data extraction and transformation.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        IBM\n",
      "   Position:       Quality Engineer\n",
      "   Start Date:     December-2017\n",
      "   End Date:       October-2018\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 13 - ID: b7e34d46-e2ed-474c-b923-103197b89dbc\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Analyst: Designed and implemented a reporting tool to pinpoint SKU opportunities at store level, contributing to a 12% increase in store-level sales by analyzing SKU performance with SQL and presenting results in Power BI.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Rubicon Organics\n",
      "   Position:       Data Analyst\n",
      "   Start Date:     March-2023\n",
      "   End Date:       December-2023\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 14 - ID: c3a7162e-d770-48d2-9288-959becd66e08\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist: Developed and deployed anomaly-detection and time-series forecasting models achieving 86% accuracy in predicting food safety risk prevalence by training models on historical data using Python and ML techniques.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist\n",
      "   Start Date:     December-2023\n",
      "   End Date:       March-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 15 - ID: c720a6e3-d140-4e1c-be22-8b500acf031b\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist: Built an unsupervised anomaly detection model to identify potential food safety risks in imported products by training unsupervised ML models using Python and applying them to imported product datasets.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist\n",
      "   Start Date:     December-2023\n",
      "   End Date:       March-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 16 - ID: cac92ec5-88a7-42ce-9426-21e50c015b30\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Data Scientist II: Implemented daily automated data refreshes, replacing weekly manual CSV exports, by gaining direct data-warehouse access and building an ETL pipeline using SQL and Microsoft Fabric to store data in a Lakehouse.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        Canadian Food Inspection Agency\n",
      "   Position:       Data Scientist II\n",
      "   Start Date:     March-2025\n",
      "   End Date:       November-2025\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 17 - ID: d212191c-b244-4d13-b871-8779474b1a6c\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Quality Assurance Technician: Automated sanitation KPI reporting using Excel and MS Forms, contributing to an 80% SQF audit score by building automated reports and forms to track sanitation metrics.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        The Very Good Food Company\n",
      "   Position:       Quality Assurance Technician\n",
      "   Start Date:     February-2021\n",
      "   End Date:       February-2022\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 18 - ID: d25720a1-f327-465e-ba04-4081e7c87aed\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Quality Engineer: Reduced hard-drive screw defects by 15% (â‰ˆ$110,000 annual savings) by extracting and cleaning 50,000+ records with SQL, performing statistical analysis in Excel, and applying Six Sigma root-cause methods.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        IBM\n",
      "   Position:       Quality Engineer\n",
      "   Start Date:     December-2017\n",
      "   End Date:       October-2018\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n",
      "================================================================================\n",
      "CHUNK 19 - ID: d8f975fb-b8bd-4426-8b72-cf2896f99927\n",
      "================================================================================\n",
      "ğŸ“„ Content (Achievement):\n",
      "   Quality Assurance Technician: Coordinated supply chain and production teams to ensure food safety compliance by leading cross-functional meetings and implementing compliance checks, maintaining operational continuity.\n",
      "\n",
      "ğŸ¢ Metadata:\n",
      "   Company:        The Very Good Food Company\n",
      "   Position:       Quality Assurance Technician\n",
      "   Start Date:     February-2021\n",
      "   End Date:       February-2022\n",
      "   Source File:    resume_ale.md\n",
      "   Section Type:   work_experience\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for work experience entries\n",
    "work_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"section_type\",\n",
    "            match=MatchValue(value=\"work_experience\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "work_records, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=work_filter,\n",
    "    limit=20,\n",
    "    with_payload=True,\n",
    "    with_vectors=False  # Set True to see embeddings\n",
    ")\n",
    "\n",
    "print(f\"ğŸ’¼ Work Experience Chunks (showing {len(work_records)}):\\n\")\n",
    "\n",
    "for i, record in enumerate(work_records, 1):\n",
    "    payload = record.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"CHUNK {i} - ID: {record.id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“„ Content (Achievement):\")\n",
    "    print(f\"   {payload.get('content', 'N/A')}\")\n",
    "    print(f\"\\nğŸ¢ Metadata:\")\n",
    "    print(f\"   Company:        {metadata.get('company', 'N/A')}\")\n",
    "    print(f\"   Position:       {metadata.get('position', 'N/A')}\")\n",
    "    print(f\"   Start Date:     {metadata.get('start_date', 'N/A')}\")\n",
    "    print(f\"   End Date:       {metadata.get('end_date', 'N/A')}\")\n",
    "    print(f\"   Source File:    {payload.get('source_file', 'N/A')}\")\n",
    "    print(f\"   Section Type:   {payload.get('section_type', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ee076",
   "metadata": {},
   "source": [
    "### 3.2 View Work Experience WITH Embeddings\n",
    "\n",
    "Each chunk has a 1536-dimensional embedding vector generated by OpenAI's `text-embedding-3-small` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5d0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¢ Embedding Vector Details:\n",
      "   Vector dimensions: 1536\n",
      "   Vector type: <class 'list'>\n",
      "   First 10 values: [-0.008849185891449451, -0.010623646900057793, 0.050725314766168594, -0.03128138184547424, -0.003268592059612274, 0.016022169962525368, -0.019386133179068565, 0.020599933341145515, 0.016264930367469788, 0.028761299327015877]\n",
      "   Last 10 values:  [0.0031183119863271713, 0.010646766982972622, 0.013074368238449097, 0.02090049348771572, 0.02324717491865158, -0.02385985665023327, -0.001502800965681672, 0.0018813912756741047, 0.02025313302874565, 0.0021877314429730177]\n",
      "\n",
      "ğŸ“Š Vector Statistics:\n",
      "   Min value:  -0.097289\n",
      "   Max value:  0.109034\n",
      "   Mean value: 0.001180\n",
      "   Std dev:    0.025488\n",
      "\n",
      "ğŸ“„ Associated Content:\n",
      "   Data Scientist II: Developed a Power BI dashboard to track changes in imported food volumes, collaborating with import inspectors to define metrics an...\n"
     ]
    }
   ],
   "source": [
    "# Get one work experience record WITH embeddings\n",
    "work_with_vector, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=work_filter,\n",
    "    limit=20,\n",
    "    with_payload=True,\n",
    "    with_vectors=True  # â† Include embeddings\n",
    ")\n",
    "\n",
    "if work_with_vector:\n",
    "    record = work_with_vector[0]\n",
    "    vector = record.vector\n",
    "    \n",
    "    print(f\"ğŸ”¢ Embedding Vector Details:\")\n",
    "    print(f\"   Vector dimensions: {len(vector)}\")\n",
    "    print(f\"   Vector type: {type(vector)}\")\n",
    "    print(f\"   First 10 values: {vector[:10]}\")\n",
    "    print(f\"   Last 10 values:  {vector[-10:]}\")\n",
    "    print(f\"\\nğŸ“Š Vector Statistics:\")\n",
    "    import numpy as np\n",
    "    vector_array = np.array(vector)\n",
    "    print(f\"   Min value:  {vector_array.min():.6f}\")\n",
    "    print(f\"   Max value:  {vector_array.max():.6f}\")\n",
    "    print(f\"   Mean value: {vector_array.mean():.6f}\")\n",
    "    print(f\"   Std dev:    {vector_array.std():.6f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“„ Associated Content:\")\n",
    "    print(f\"   {record.payload.get('content', 'N/A')[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058d26e",
   "metadata": {},
   "source": [
    "### 3.3 Query Education & Skills Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef4b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Education Entries (2):\n",
      "\n",
      "================================================================================\n",
      "EDUCATION CHUNK 1\n",
      "================================================================================\n",
      "ğŸ“ Degree:        BSc in Biotechnology Engineering\n",
      "ğŸ« Institution:   Tec de Monterrey\n",
      "ğŸ“… Year:          N/A\n",
      "ğŸ“‚ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  education\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   BSc in Biotechnology Engineering from Tec de Monterrey. August-2012 - May-2017 | Mexico\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"degree\": \"BSc in Biotechnology Engineering\",\n",
      "  \"institution\": \"Tec de Monterrey\",\n",
      "  \"dates\": \"August-2012 - May-2017 | Mexico\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "EDUCATION CHUNK 2\n",
      "================================================================================\n",
      "ğŸ“ Degree:        MSc in Food Science\n",
      "ğŸ« Institution:   University of British Columbia\n",
      "ğŸ“… Year:          N/A\n",
      "ğŸ“‚ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  education\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   MSc in Food Science from University of British Columbia. January-2019 - October-2020 | Canada\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"degree\": \"MSc in Food Science\",\n",
      "  \"institution\": \"University of British Columbia\",\n",
      "  \"dates\": \"January-2019 - October-2020 | Canada\"\n",
      "}\n",
      "\n",
      "\n",
      "ğŸ› ï¸  Skills Entries (5):\n",
      "\n",
      "================================================================================\n",
      "SKILL CHUNK 1\n",
      "================================================================================\n",
      "ğŸ“‚ Category:      Methodologies\n",
      "ğŸ“„ Skills:        Methodologies: Agile, Six Sigma\n",
      "ğŸ“ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  skills\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"category\": \"Methodologies\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "SKILL CHUNK 2\n",
      "================================================================================\n",
      "ğŸ“‚ Category:      Development Tools\n",
      "ğŸ“„ Skills:        Development Tools: Git, Docker, Azure DevOps, VS Code, API\n",
      "ğŸ“ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  skills\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"category\": \"Development Tools\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "SKILL CHUNK 3\n",
      "================================================================================\n",
      "ğŸ“‚ Category:      Business Intelligence\n",
      "ğŸ“„ Skills:        Business Intelligence: Power BI, Microsoft Fabric, OneLake, Power Query, Power Pivot, Excel, Delta Lake\n",
      "ğŸ“ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  skills\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"category\": \"Business Intelligence\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "SKILL CHUNK 4\n",
      "================================================================================\n",
      "ğŸ“‚ Category:      Programming Languages\n",
      "ğŸ“„ Skills:        Programming Languages: Python, SQL, PySpark, T-SQL\n",
      "ğŸ“ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  skills\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"category\": \"Programming Languages\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "SKILL CHUNK 5\n",
      "================================================================================\n",
      "ğŸ“‚ Category:      Cloud Platforms\n",
      "ğŸ“„ Skills:        Cloud Platforms: Azure, Google Cloud\n",
      "ğŸ“ Source File:   resume_ale.md\n",
      "ğŸ·ï¸  Section Type:  skills\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"category\": \"Cloud Platforms\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query education entries\n",
    "education_filter = Filter(\n",
    "    must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"education\"))]\n",
    ")\n",
    "\n",
    "education_records, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=education_filter,\n",
    "    limit=20,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“ Education Entries ({len(education_records)}):\\n\")\n",
    "for i, record in enumerate(education_records, 1):\n",
    "    payload = record.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"EDUCATION CHUNK {i}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“ Degree:        {metadata.get('degree', 'N/A')}\")\n",
    "    print(f\"ğŸ« Institution:   {metadata.get('institution', 'N/A')}\")\n",
    "    print(f\"ğŸ“… Year:          {metadata.get('year', 'N/A')}\")\n",
    "    print(f\"ğŸ“‚ Source File:   {payload.get('source_file', 'N/A')}\")\n",
    "    print(f\"ğŸ·ï¸  Section Type:  {payload.get('section_type', 'N/A')}\")\n",
    "    print(f\"\\nğŸ“„ Content:\\n   {payload.get('content', 'N/A')}\")\n",
    "    print(f\"\\nğŸ” Full Metadata: {json.dumps(metadata, indent=2)}\")\n",
    "    print()\n",
    "\n",
    "# Query skills\n",
    "skills_filter = Filter(\n",
    "    must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"skills\"))]\n",
    ")\n",
    "\n",
    "skills_records, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=skills_filter,\n",
    "    limit=20,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ› ï¸  Skills Entries ({len(skills_records)}):\\n\")\n",
    "for i, record in enumerate(skills_records, 1):\n",
    "    payload = record.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"SKILL CHUNK {i}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“‚ Category:      {metadata.get('category', 'N/A')}\")\n",
    "    print(f\"ğŸ“„ Skills:        {payload.get('content', 'N/A')}\")\n",
    "    print(f\"ğŸ“ Source File:   {payload.get('source_file', 'N/A')}\")\n",
    "    print(f\"ğŸ·ï¸  Section Type:  {payload.get('section_type', 'N/A')}\")\n",
    "    print(f\"\\nğŸ” Full Metadata: {json.dumps(metadata, indent=2)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c60b4",
   "metadata": {},
   "source": [
    "## 4. Query Personality Traits Data (from personalities_16.md)\n",
    "\n",
    "### 4.1 View Personality Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d24204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Personality Trait Chunks (14):\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 1\n",
      "================================================================================\n",
      "ğŸ“ Section:       Big-Picture Focus\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I prefer focusing on overarching goals and strategies rather than micromanaging small details.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Big-Picture Focus\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 2\n",
      "================================================================================\n",
      "ğŸ“ Section:       Conceptual Thinking\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I effortlessly grasp abstract, complex ideas, making me particularly suited to roles that require strategic analysis and long-term planning.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Conceptual Thinking\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 3\n",
      "================================================================================\n",
      "ğŸ“ Section:       Innovative Mindset\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   My ability to see possibilities others overlook often helps me find smarter solutions and effective improvements at work.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Innovative Mindset\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 4\n",
      "================================================================================\n",
      "ğŸ“ Section:       Frustration with Constraints\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I chafe at rules or procedures I deem pointless, potentially straining relationships with supervisors or organizational hierarchy.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Frustration with Constraints\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 5\n",
      "================================================================================\n",
      "ğŸ“ Section:       Objective Judgment\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   My capacity to make impartial decisions based on facts rather than favoritism or personal bias earns respect and trust from my colleagues.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Objective Judgment\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 6\n",
      "================================================================================\n",
      "ğŸ“ Section:       Overly Blunt Feedback\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   In my pursuit of truth and efficiency, I may deliver criticisms in ways that unintentionally demotivate or upset sensitive colleagues.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Overly Blunt Feedback\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 7\n",
      "================================================================================\n",
      "ğŸ“ Section:       Ignoring Social Dynamics\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I tend to neglect office politics and informal social interactions, possibly missing cues or causing unintended misunderstandings.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Ignoring Social Dynamics\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 8\n",
      "================================================================================\n",
      "ğŸ“ Section:       Reluctance to Delegate Tasks\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   Believing strongly in my own abilities, I often hesitate to entrust responsibilities to others, leading to stress or unnecessary workload.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Reluctance to Delegate Tasks\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 9\n",
      "================================================================================\n",
      "ğŸ“ Section:       Reliable Performance\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   When entrusted with critical tasks, I consistently deliver precise, high-quality results, making me a valued and dependable asset.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Reliable Performance\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 10\n",
      "================================================================================\n",
      "ğŸ“ Section:       Goal-Oriented\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I stay motivated by clear goals and visible progress, consistently tracking achievements and identifying next steps. # Weaknesses My preference for working independently and my dislike for office politics can sometimes hinder my career progression. I need to learn to navigate social dynamics and communicate my ideas effectively to others for my professional growth. My unique insights are most valuable when they can be implemented, which often requires collaboration and buy-in from others.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Goal-Oriented\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 11\n",
      "================================================================================\n",
      "ğŸ“ Section:       Independent Worker\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   My talent for working productively on my own allows me to manage tasks effectively without the need for constant direction or supervision.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Independent Worker\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 12\n",
      "================================================================================\n",
      "ğŸ“ Section:       Impatience with Routine\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I often feel restless when assigned tasks that seem repetitive or mundane, leading to occasional lapses in my attention or motivation.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Impatience with Routine\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 13\n",
      "================================================================================\n",
      "ğŸ“ Section:       Discomfort with Networking\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   My aversion to promoting myself or making connections can limit career advancement opportunities, hiding my true worth from others.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Discomfort with Networking\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "PERSONALITY CHUNK 14\n",
      "================================================================================\n",
      "ğŸ“ Section:       Continuous Improvement\n",
      "ğŸ“‚ Source File:   personalities_16.md\n",
      "ğŸ·ï¸  Section Type:  personality\n",
      "\n",
      "ğŸ“„ Content:\n",
      "   I naturally focus on refining work processes and spotting inefficiencies, consistently improving project outcomes wherever I go.\n",
      "\n",
      "ğŸ” Full Metadata: {\n",
      "  \"section\": \"Continuous Improvement\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query personality trait chunks (main sections like \"Personality Traits\", \"Career Preferences\")\n",
    "personality_filter = Filter(\n",
    "    must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"personality\"))]\n",
    ")\n",
    "\n",
    "personality_records, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=personality_filter,\n",
    "    limit=20,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ§  Personality Trait Chunks ({len(personality_records)}):\\n\")\n",
    "\n",
    "for i, record in enumerate(personality_records, 1):\n",
    "    payload = record.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"PERSONALITY CHUNK {i}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“ Section:       {metadata.get('section', 'N/A')}\")\n",
    "    print(f\"ğŸ“‚ Source File:   {payload.get('source_file', 'N/A')}\")\n",
    "    print(f\"ğŸ·ï¸  Section Type:  {payload.get('section_type', 'N/A')}\")\n",
    "    print(f\"\\nğŸ“„ Content:\\n   {payload.get('content', 'N/A')}\")\n",
    "    print(f\"\\nğŸ” Full Metadata: {json.dumps(metadata, indent=2)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b01149",
   "metadata": {},
   "source": [
    "### 4.2 View Strength Chunks\n",
    "\n",
    "Strengths are subsections (### headers) under the main \"Strengths\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e6112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’ª Strength Chunks (0):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query strength chunks\n",
    "strength_filter = Filter(\n",
    "    must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"strength\"))]\n",
    ")\n",
    "\n",
    "strength_records, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=strength_filter,\n",
    "    limit=10,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ’ª Strength Chunks ({len(strength_records)}):\\n\")\n",
    "\n",
    "for i, record in enumerate(strength_records, 1):\n",
    "    payload = record.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"STRENGTH {i}: {metadata.get('subsection', 'N/A')}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“ Parent Section: {metadata.get('section', 'N/A')}\")\n",
    "    print(f\"ğŸ“Œ Subsection:     {metadata.get('subsection', 'N/A')}\")\n",
    "    print(f\"ğŸ“‚ Source File:    {payload.get('source_file', 'N/A')}\")\n",
    "    print(f\"ğŸ·ï¸  Section Type:   {payload.get('section_type', 'N/A')}\")\n",
    "    print(f\"\\nğŸ“„ Content:\\n   {payload.get('content', 'N/A')}\")\n",
    "    print(f\"\\nğŸ” Full Metadata: {json.dumps(metadata, indent=2)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13bd59",
   "metadata": {},
   "source": [
    "### 4.3 View Weakness Chunks (Excluded from Cover Letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7f794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Weakness Chunks (0):\n",
      "   (Note: These are intentionally EXCLUDED from cover letter retrieval)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query weakness chunks (these are stored but NOT retrieved for cover letters)\n",
    "weakness_filter = Filter(\n",
    "    must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"weakness\"))]\n",
    ")\n",
    "\n",
    "weakness_records, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=weakness_filter,\n",
    "    limit=10,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"âš ï¸  Weakness Chunks ({len(weakness_records)}):\")\n",
    "print(f\"   (Note: These are intentionally EXCLUDED from cover letter retrieval)\\n\")\n",
    "\n",
    "for i, record in enumerate(weakness_records, 1):\n",
    "    payload = record.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"WEAKNESS {i}: {metadata.get('subsection', 'N/A')}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“ Parent Section: {metadata.get('section', 'N/A')}\")\n",
    "    print(f\"ğŸ“Œ Subsection:     {metadata.get('subsection', 'N/A')}\")\n",
    "    print(f\"ğŸ“‚ Source File:    {payload.get('source_file', 'N/A')}\")\n",
    "    print(f\"ğŸ·ï¸  Section Type:   {payload.get('section_type', 'N/A')}\")\n",
    "    print(f\"\\nğŸ“„ Content:\\n   {payload.get('content', 'N/A')}\")\n",
    "    print(f\"\\nğŸ” Full Metadata: {json.dumps(metadata, indent=2)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbfb16d",
   "metadata": {},
   "source": [
    "## 5. Semantic Search Examples\n",
    "\n",
    "### 5.1 Search for Python-Related Work Experience\n",
    "\n",
    "This demonstrates how semantic search works with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9e2eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Semantic Search Query: 'Python data analysis ETL pipeline machine learning'\n",
      "   Query vector dimensions: 1536\n",
      "\n",
      "ğŸ“Š Top 4 Results (by semantic similarity):\n",
      "\n",
      "================================================================================\n",
      "RESULT 1 - Similarity Score: 0.6339\n",
      "================================================================================\n",
      "ğŸ“„ Content: Data Analyst: Built an ETL pipeline integrating five data sources totaling over 1M records using SQL and Python, automating ingestion and cleaning and saving 8 hours weekly in data preparation.\n",
      "ğŸ·ï¸  Section Type: work_experience\n",
      "   Company: Rubicon Organics\n",
      "   Position: Data Analyst\n",
      "\n",
      "================================================================================\n",
      "RESULT 2 - Similarity Score: 0.5509\n",
      "================================================================================\n",
      "ğŸ“„ Content: Data Scientist II: Extracted and processed millions of import/export transactions by building web-scraping collectors and a PySpark ETL pipeline to load cleaned data into a Microsoft Fabric lakehouse.\n",
      "ğŸ·ï¸  Section Type: work_experience\n",
      "   Company: Canadian Food Inspection Agency\n",
      "   Position: Data Scientist II\n",
      "\n",
      "================================================================================\n",
      "RESULT 3 - Similarity Score: 0.5154\n",
      "================================================================================\n",
      "ğŸ“„ Content: Data Scientist II: Automated data categorization, reducing data cleaning time by over 15 hours per week, by integrating LLM-based classification into the ETL pipeline.\n",
      "ğŸ·ï¸  Section Type: work_experience\n",
      "   Company: Canadian Food Inspection Agency\n",
      "   Position: Data Scientist II\n",
      "\n",
      "================================================================================\n",
      "RESULT 4 - Similarity Score: 0.5121\n",
      "================================================================================\n",
      "ğŸ“„ Content: Data Scientist II: Implemented daily automated data refreshes, replacing weekly manual CSV exports, by gaining direct data-warehouse access and building an ETL pipeline using SQL and Microsoft Fabric to store data in a Lakehouse.\n",
      "ğŸ·ï¸  Section Type: work_experience\n",
      "   Company: Canadian Food Inspection Agency\n",
      "   Position: Data Scientist II\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAI embeddings to create query vectors\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.core.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "# Create a query for Python-related achievements\n",
    "query_text = \"Python data analysis ETL pipeline machine learning\"\n",
    "query_vector = embedder.embed_query(query_text)\n",
    "\n",
    "print(f\"ğŸ” Semantic Search Query: '{query_text}'\")\n",
    "print(f\"   Query vector dimensions: {len(query_vector)}\")\n",
    "\n",
    "# Search with vector similarity using query_points (newer API)\n",
    "results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=5,\n",
    "    score_threshold=0.5  # Only return results with similarity > 0.5\n",
    ").points\n",
    "\n",
    "print(f\"\\nğŸ“Š Top {len(results)} Results (by semantic similarity):\\n\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    payload = result.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"RESULT {i} - Similarity Score: {result.score:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“„ Content: {payload.get('content', 'N/A')}\")\n",
    "    print(f\"ğŸ·ï¸  Section Type: {payload.get('section_type', 'N/A')}\")\n",
    "    if payload.get('section_type') == 'work_experience':\n",
    "        print(f\"   Company: {metadata.get('company', 'N/A')}\")\n",
    "        print(f\"   Position: {metadata.get('position', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe440754",
   "metadata": {},
   "source": [
    "### 5.2 Search for Personality Traits Matching Job Requirements\n",
    "\n",
    "This mimics how `retrieve_personality_traits()` works in the resume generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "114100a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Job Requirements Query: 'analytical thinking problem-solving collaboration strategic innovative team player'\n",
      "\n",
      "ğŸ“Š Retrieved 5 Personality/Strength Traits:\n",
      "\n",
      "================================================================================\n",
      "TRAIT 1 - Similarity: 0.4947\n",
      "================================================================================\n",
      "ğŸ·ï¸  Type: personality\n",
      "ğŸ“ Section: Conceptual Thinking\n",
      "ğŸ“„ Content:\n",
      "   I effortlessly grasp abstract, complex ideas, making me particularly suited to roles that require strategic analysis and long-term planning.\n",
      "\n",
      "================================================================================\n",
      "TRAIT 2 - Similarity: 0.4716\n",
      "================================================================================\n",
      "ğŸ·ï¸  Type: personality\n",
      "ğŸ“ Section: Innovative Mindset\n",
      "ğŸ“„ Content:\n",
      "   My ability to see possibilities others overlook often helps me find smarter solutions and effective improvements at work.\n",
      "\n",
      "================================================================================\n",
      "TRAIT 3 - Similarity: 0.4082\n",
      "================================================================================\n",
      "ğŸ·ï¸  Type: personality\n",
      "ğŸ“ Section: Goal-Oriented\n",
      "ğŸ“„ Content:\n",
      "   I stay motivated by clear goals and visible progress, consistently tracking achievements and identifying next steps. # Weaknesses My preference for working independently and my dislike for office politics can sometimes hinder my career progression. I need to learn to navigate social dynamics and communicate my ideas effectively to others for my professional growth. My unique insights are most valuable when they can be implemented, which often requires collaboration and buy-in from others.\n",
      "\n",
      "================================================================================\n",
      "TRAIT 4 - Similarity: 0.3797\n",
      "================================================================================\n",
      "ğŸ·ï¸  Type: personality\n",
      "ğŸ“ Section: Continuous Improvement\n",
      "ğŸ“„ Content:\n",
      "   I naturally focus on refining work processes and spotting inefficiencies, consistently improving project outcomes wherever I go.\n",
      "\n",
      "================================================================================\n",
      "TRAIT 5 - Similarity: 0.3725\n",
      "================================================================================\n",
      "ğŸ·ï¸  Type: personality\n",
      "ğŸ“ Section: Reliable Performance\n",
      "ğŸ“„ Content:\n",
      "   When entrusted with critical tasks, I consistently deliver precise, high-quality results, making me a valued and dependable asset.\n",
      "\n",
      "\n",
      "ğŸ’¡ These traits would be injected into the cover letter prompt!\n"
     ]
    }
   ],
   "source": [
    "# Simulate a job analysis with soft skills and keywords\n",
    "job_analysis = {\n",
    "    'soft_skills': ['analytical thinking', 'problem-solving', 'collaboration'],\n",
    "    'keywords': ['strategic', 'innovative', 'team player']\n",
    "}\n",
    "\n",
    "# Build query (same logic as retrieve_personality_traits)\n",
    "query_parts = job_analysis.get('soft_skills', []) + job_analysis.get('keywords', [])\n",
    "query_text = ' '.join(query_parts)\n",
    "query_vector = embedder.embed_query(query_text)\n",
    "\n",
    "print(f\"ğŸ” Job Requirements Query: '{query_text}'\\n\")\n",
    "\n",
    "# Search all sections first\n",
    "all_results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=10\n",
    ").points\n",
    "\n",
    "# Filter for personality/strength only (mimics retrieve_personality_traits)\n",
    "personality_results = [\n",
    "    r for r in all_results \n",
    "    if r.payload.get('section_type') in ['personality', 'strength']\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“Š Retrieved {len(personality_results)} Personality/Strength Traits:\\n\")\n",
    "\n",
    "for i, result in enumerate(personality_results[:5], 1):  # Top 5\n",
    "    payload = result.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"TRAIT {i} - Similarity: {result.score:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ·ï¸  Type: {payload.get('section_type', 'N/A')}\")\n",
    "    print(f\"ğŸ“ Section: {metadata.get('section', 'N/A')}\")\n",
    "    if metadata.get('subsection'):\n",
    "        print(f\"   Subsection: {metadata.get('subsection', 'N/A')}\")\n",
    "    print(f\"ğŸ“„ Content:\\n   {payload.get('content', 'N/A')}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nğŸ’¡ These traits would be injected into the cover letter prompt!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b67c13",
   "metadata": {},
   "source": [
    "### 5.3 Semantic Search with Section Filtering\n",
    "\n",
    "Combine semantic search with metadata filters for precise results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "096b45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Query: 'data science machine learning SQL Python dashboard visualization'\n",
      "ğŸ¯ Filter: section_type = 'work_experience'\n",
      "\n",
      "ğŸ“Š Top 5 Work Achievements:\n",
      "\n",
      "1. [Score: 0.5815] Canadian Food Inspection Agency - Data Scientist\n",
      "   Data Scientist: Standardized descriptive and statistical reporting in Power BI, reducing report-gene...\n",
      "\n",
      "2. [Score: 0.5102] Rubicon Organics - Data Analyst\n",
      "   Data Analyst: Built an ETL pipeline integrating five data sources totaling over 1M records using SQL...\n",
      "\n",
      "3. [Score: 0.5098] Rubicon Organics - Data Analyst\n",
      "   Data Analyst: Built three Power BI dashboards for sales and marketing by collaborating with stakehol...\n",
      "\n",
      "4. [Score: 0.4951] Canadian Food Inspection Agency - Data Scientist II\n",
      "   Data Scientist II: Automated forecasting and reduced manual effort by 40 hours per month by deployin...\n",
      "\n",
      "5. [Score: 0.4918] Canadian Food Inspection Agency - Data Scientist II\n",
      "   Data Scientist II: Implemented daily automated data refreshes, replacing weekly manual CSV exports, ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for data science achievements ONLY in work experience\n",
    "query_text = \"data science machine learning SQL Python dashboard visualization\"\n",
    "query_vector = embedder.embed_query(query_text)\n",
    "\n",
    "# Apply filter to only search work_experience\n",
    "work_filter = Filter(\n",
    "    must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"work_experience\"))]\n",
    ")\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    query_filter=work_filter,  # â† Apply filter during search\n",
    "    limit=5\n",
    ").points\n",
    "\n",
    "print(f\"ğŸ” Query: '{query_text}'\")\n",
    "print(f\"ğŸ¯ Filter: section_type = 'work_experience'\")\n",
    "print(f\"\\nğŸ“Š Top {len(results)} Work Achievements:\\n\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    payload = result.payload\n",
    "    metadata = payload.get('metadata', {})\n",
    "    \n",
    "    print(f\"{i}. [Score: {result.score:.4f}] {metadata.get('company', 'N/A')} - {metadata.get('position', 'N/A')}\")\n",
    "    print(f\"   {payload.get('content', 'N/A')[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518991b",
   "metadata": {},
   "source": [
    "## 6. Complete RAG Workflow Example\n",
    "\n",
    "This demonstrates the full retrieval flow used in resume generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6753e9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE RAG WORKFLOW: Data Scientist Position\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ Job: Senior Data Scientist at Tech Corp\n",
      "ğŸ“ Requirements: Python, ML, SQL, data viz, analytical thinking, communication\n",
      "\n",
      "================================================================================\n",
      "PHASE 1: RETRIEVAL (Vector Similarity Search)\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Retrieved 10 relevant work achievements:\n",
      "   1. [0.452] Canadian Food Inspection Agency - Data Scientist II: Extracted and processed millions of impor...\n",
      "   2. [0.448] Canadian Food Inspection Agency - Data Scientist: Standardized descriptive and statistical rep...\n",
      "   3. [0.448] Canadian Food Inspection Agency - Data Scientist II: Implemented daily automated data refreshe...\n",
      "   4. [0.441] Canadian Food Inspection Agency - Data Scientist: Analyzed pathogen occurrence trends across 5...\n",
      "   5. [0.433] Rubicon Organics - Data Analyst: Built an ETL pipeline integrating five data so...\n",
      "\n",
      "ğŸ§  Retrieved 0 personality traits:\n",
      "\n",
      "================================================================================\n",
      "PHASE 2: AUGMENTATION (Combine Context)\n",
      "================================================================================\n",
      "\n",
      "âœ… Would combine:\n",
      "   - Job requirements: Senior Data Scientist, Python, ML, SQL...\n",
      "   - 5 work achievements\n",
      "   - 0 personality traits\n",
      "   - Into a structured prompt for Claude\n",
      "\n",
      "================================================================================\n",
      "PHASE 3: GENERATION (Claude LLM)\n",
      "================================================================================\n",
      "\n",
      "âœ… Would call Claude API with augmented prompt to generate:\n",
      "   - Tailored resume sections\n",
      "   - Personalized cover letter\n",
      "   - Using ONLY the retrieved context\n",
      "\n",
      "================================================================================\n",
      "âœ… RAG WORKFLOW COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Simulate a complete RAG workflow for a Data Scientist job\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE RAG WORKFLOW: Data Scientist Position\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Job context\n",
    "job_title = \"Senior Data Scientist\"\n",
    "company = \"Tech Corp\"\n",
    "job_description = \"\"\"\n",
    "Looking for a data scientist with strong Python skills, experience with machine learning,\n",
    "SQL databases, and data visualization. Must have excellent analytical and problem-solving\n",
    "abilities with strong communication skills.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nğŸ“‹ Job: {job_title} at {company}\")\n",
    "print(f\"ğŸ“ Requirements: Python, ML, SQL, data viz, analytical thinking, communication\\n\")\n",
    "\n",
    "# 2. PHASE 1: RETRIEVAL\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 1: RETRIEVAL (Vector Similarity Search)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create query embedding\n",
    "query_text = f\"{job_title} {company} {job_description}\"\n",
    "query_vector = embedder.embed_query(query_text)\n",
    "\n",
    "# Retrieve work experience\n",
    "work_results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    query_filter=Filter(\n",
    "        must=[FieldCondition(key=\"section_type\", match=MatchValue(value=\"work_experience\"))]\n",
    "    ),\n",
    "    limit=10\n",
    ").points\n",
    "\n",
    "print(f\"\\nğŸ” Retrieved {len(work_results)} relevant work achievements:\")\n",
    "for i, result in enumerate(work_results[:5], 1):\n",
    "    metadata = result.payload.get('metadata', {})\n",
    "    print(f\"   {i}. [{result.score:.3f}] {metadata.get('company')} - {result.payload.get('content', '')[:60]}...\")\n",
    "\n",
    "# Retrieve personality traits\n",
    "job_analysis = {\n",
    "    'soft_skills': ['analytical', 'problem-solving', 'communication'],\n",
    "    'keywords': ['data-driven', 'collaborative']\n",
    "}\n",
    "\n",
    "personality_query = ' '.join(job_analysis['soft_skills'] + job_analysis['keywords'])\n",
    "personality_vector = embedder.embed_query(personality_query)\n",
    "\n",
    "personality_results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=personality_vector,\n",
    "    limit=10\n",
    ").points\n",
    "\n",
    "# Filter for personality/strength\n",
    "personality_filtered = [\n",
    "    r for r in personality_results \n",
    "    if r.payload.get('section_type') in ['personality', 'strength']\n",
    "][:5]\n",
    "\n",
    "print(f\"\\nğŸ§  Retrieved {len(personality_filtered)} personality traits:\")\n",
    "for i, result in enumerate(personality_filtered, 1):\n",
    "    print(f\"   {i}. [{result.score:.3f}] {result.payload.get('content', '')[:60]}...\")\n",
    "\n",
    "# 3. PHASE 2: AUGMENTATION\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 2: AUGMENTATION (Combine Context)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… Would combine:\")\n",
    "print(f\"   - Job requirements: {job_title}, Python, ML, SQL...\")\n",
    "print(f\"   - {len(work_results[:5])} work achievements\")\n",
    "print(f\"   - {len(personality_filtered)} personality traits\")\n",
    "print(\"   - Into a structured prompt for Claude\")\n",
    "\n",
    "# 4. PHASE 3: GENERATION\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PHASE 3: GENERATION (Claude LLM)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… Would call Claude API with augmented prompt to generate:\")\n",
    "print(\"   - Tailored resume sections\")\n",
    "print(\"   - Personalized cover letter\")\n",
    "print(\"   - Using ONLY the retrieved context\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"âœ… RAG WORKFLOW COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721c8f5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Collection Structure**: Viewing all collections, document counts, and section types\n",
    "2. **Resume Data Queries**: Filtering work experience, education, skills with full metadata\n",
    "3. **Personality Data Queries**: Viewing personality, strength, and weakness chunks\n",
    "4. **Embeddings**: Inspecting 1536-dimensional vectors and their statistics\n",
    "5. **Semantic Search**: Using OpenAI embeddings for similarity-based retrieval\n",
    "6. **Section Filtering**: Combining semantic search with metadata filters\n",
    "7. **Complete RAG Flow**: End-to-end retrieval â†’ augmentation â†’ generation workflow\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Chunking preserves context**: Each chunk contains a complete semantic unit (achievement, trait, skill)\n",
    "- **Embeddings enable semantic matching**: Query \"machine learning\" matches \"ML model\", \"predictive analytics\"\n",
    "- **Metadata enables filtering**: Can retrieve only work experience, only strengths, etc.\n",
    "- **Similarity scores guide selection**: Higher scores = more relevant to query\n",
    "- **Weaknesses are excluded**: `retrieve_personality_traits()` filters out `section_type='weakness'`\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run cells to explore your actual vector database\n",
    "- Modify queries to test different job requirements\n",
    "- Experiment with `score_threshold` values\n",
    "- Try combining multiple filters (e.g., company + section_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Resume_Claude_SDK_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
